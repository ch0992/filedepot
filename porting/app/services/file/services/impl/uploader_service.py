"""
[ğŸ“„ uploader_service.py - File ì„œë¹„ìŠ¤ êµ¬í˜„ì²´]

ì„¤ëª…:
- íŒŒì¼ ì—…ë¡œë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤ êµ¬í˜„ì²´
- ì‚¬ìš©ì ID, íŒŒì¼, í† í”½ëª…ì„ ë°›ì•„ ì—…ë¡œë“œ ì²˜ë¦¬

ì£¼ìš” ì—°ë™:
- UploaderInterface (ì¸í„°í˜ì´ìŠ¤)
"""

from fastapi import UploadFile
from app.services.file.services.interfaces.uploader_interface import UploaderInterface
from app.services.file.schemas.upload import UploadResponse
import aiofiles
import uuid
import os
import logging
from app.core.config import settings
from app.services.file.services.impl.minio_memory_client import MinioMemoryClient
from app.services.file.services.impl.minio_prod_client import MinioProdClient

logger = logging.getLogger("file-upload")

class UploaderService(UploaderInterface):
    async def upload_file(self, file: UploadFile):
        filename = f"{uuid.uuid4()}_{file.filename}"
        bucket = "filedepot-bucket"
        key = filename
        chunk_size = 20 * 1024 * 1024  # 20MB

        # í™˜ê²½ì— ë”°ë¼ í´ë¼ì´ì–¸íŠ¸ ì„ íƒ
        if settings.ENV in ["production", "stage"]:
            minio_client = MinioProdClient()
        else:
            minio_client = MinioMemoryClient()

        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (aiofiles í™œìš©)
        temp_path = f"/tmp/{filename}"
        async with aiofiles.open(temp_path, 'wb') as out_file:
            while True:
                chunk = await file.read(chunk_size)
                if not chunk:
                    break
                await out_file.write(chunk)

        file_size = os.path.getsize(temp_path)
        from app.common.kafka_producer import KafkaMessageProducer
        if file_size < chunk_size:
            # ë‹¨ì¼ ì—…ë¡œë“œ(20MB ë¯¸ë§Œ)
            async with aiofiles.open(temp_path, 'rb') as f:
                data = await f.read()
                location = minio_client.upload_file(bucket, key, data)
                os.remove(temp_path)
                producer = KafkaMessageProducer()
                kafka_result = await producer.produce("file_metadata", {"filename": filename, "location": location})
                # ê²€ìˆ˜(ë¬´ì¡°ê±´ ì„±ê³µìœ¼ë¡œ ê°€ì •)
                if settings.ENV in ["production", "stage"]:
                    # TODO: ì‹¤ì œ ê²€ìˆ˜/ë¬´ê²°ì„± ê²€ì‚¬ ì¸í„°í˜ì´ìŠ¤ í˜¸ì¶œ
                    logger.info(f"[ê²€ìˆ˜] íŒŒì¼ {filename} ì—…ë¡œë“œ í›„ ë¬´ê²°ì„± ê²€ì¦ (ì‹¤ì„œë¹„ìŠ¤)")
                else:
                    logger.info(f"[ê²€ìˆ˜] íŒŒì¼ {filename} ì—…ë¡œë“œ í›„ ë¬´ê²°ì„± ê²€ì¦ (dummy)")
                return UploadResponse(filename=filename, status="uploaded", location=location, kafka_result=kafka_result)
        else:
            # multipart upload (20MB ì´ìƒ)
            logger.info(f"[ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ ì‹œì‘] íŒŒì¼ëª…={filename}, ì „ì²´ìš©ëŸ‰={file_size} bytes, chunk={chunk_size} bytes")
            # ì§„í–‰ë¥  ì‹œê°í™”
            uploaded = 0
            with open(temp_path, "rb") as f:
                part_num = 1
                while True:
                    chunk = f.read(chunk_size)
                    if not chunk:
                        break
                    minio_client.upload_file(bucket, f"{key}.part{part_num}", chunk)
                    uploaded += len(chunk)
                    percent = int(uploaded / file_size * 100)
                    logger.info(f"[ì—…ë¡œë“œ ì§„í–‰] {uploaded}/{file_size} bytes ({percent}%) part={part_num}")
                    part_num += 1
            # ì‹¤ì œë¡œëŠ” multipart_uploadë¡œ í•©ì³ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„  ë‹¨ìˆœí™”
            location = f"memory://{bucket}/{key}" if settings.ENV not in ["production", "stage"] else f"s3://{bucket}/{key}"
            os.remove(temp_path)
            producer = KafkaMessageProducer()
            kafka_result = await producer.produce("file_metadata", {"filename": filename, "location": location})
            # ê²€ìˆ˜(ë¬´ì¡°ê±´ ì„±ê³µìœ¼ë¡œ ê°€ì •)
            if settings.ENV in ["production", "stage"]:
                # TODO: ì‹¤ì œ ê²€ìˆ˜/ë¬´ê²°ì„± ê²€ì‚¬ ì¸í„°í˜ì´ìŠ¤ í˜¸ì¶œ
                logger.info(f"[ê²€ìˆ˜] íŒŒì¼ {filename} ì—…ë¡œë“œ í›„ ë¬´ê²°ì„± ê²€ì¦ (ì‹¤ì„œë¹„ìŠ¤)")
            else:
                logger.info(f"[ê²€ìˆ˜] íŒŒì¼ {filename} ì—…ë¡œë“œ í›„ ë¬´ê²°ì„± ê²€ì¦ (dummy)")
            logger.info(f"[ë©€í‹°íŒŒíŠ¸ ì—…ë¡œë“œ ì™„ë£Œ] íŒŒì¼ëª…={filename}, ì „ì²´ìš©ëŸ‰={file_size} bytes")
            return UploadResponse(filename=filename, status="uploaded", location=location, kafka_result=kafka_result)


